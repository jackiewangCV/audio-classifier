{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34102,"status":"ok","timestamp":1724161413335,"user":{"displayName":"Student SE","userId":"15057726547341965574"},"user_tz":-300},"id":"zQWDZGtTbT2S","outputId":"9d672728-d995-41a6-da1f-d2ed4fc6ad00"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4037,"status":"ok","timestamp":1724161417360,"user":{"displayName":"Student SE","userId":"15057726547341965574"},"user_tz":-300},"id":"XPBN4vhsayqZ"},"outputs":[],"source":["import glob\n","import os\n","import numpy as np\n","import librosa\n","import sys\n","import tensorflow as tf\n","from keras.models import load_model\n","\n","target_length = 3341"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":43,"status":"ok","timestamp":1724161417360,"user":{"displayName":"Student SE","userId":"15057726547341965574"},"user_tz":-300},"id":"lWu8W9Swb3IG"},"outputs":[],"source":["os.chdir('/content/drive/MyDrive/Projects/AlarmWaterClassification')"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":441,"status":"ok","timestamp":1724161585519,"user":{"displayName":"Student SE","userId":"15057726547341965574"},"user_tz":-300},"id":"N0qvX61Ma8qY"},"outputs":[],"source":["def pad_features(features, target_length):\n","    if len(features) < target_length:\n","        padded_features = np.zeros((target_length, 1))\n","        padded_features[:len(features), 0] = features\n","    else:\n","        padded_features = features[:target_length]\n","        padded_features = padded_features.reshape(-1, 1)  # Ensure it has the shape (timesteps, channels)\n","    return padded_features\n","\n","def get_STFT(file, trim_flag=False, same_training=False):\n","    audio_data, sample_rate = librosa.load(file, sr=16000)\n","\n","    zero_data = np.zeros((160,))\n","    audio_data = zero_data.tolist() + audio_data.tolist()\n","    audio_data = np.array(audio_data)\n","    audio_data[480:512] = 0\n","    reduced_noise = audio_data\n","\n","    trimmed = reduced_noise\n","    if trim_flag or same_training:\n","        trimmed, index = librosa.effects.trim(reduced_noise, top_db=20, frame_length=512, hop_length=64)\n","    # extract features\n","    if same_training:\n","        stft = np.abs(librosa.stft(trimmed, n_fft=512, hop_length=256, win_length=512))\n","    else:\n","        stft = np.abs(librosa.stft(trimmed, n_fft=512, hop_length=320, win_length=480, center=False))\n","\n","    return stft\n","\n","\n","def convert_keras2qttflite(feature_folder, keras_model_file, tflite_model_file):\n","    def representative_dataset_test():\n","        list_np = glob.glob(f\"{feature_folder}/**/*.npy\", recursive=True)\n","        for np_f in list_np:\n","            np_data = np.load(np_f)\n","            np_data = np.array(np_data, dtype=np.float32, ndmin=2)\n","            yield [np.expand_dims(np_data, axis=0)]\n","\n","    keras_model = load_model(keras_model_file)\n","    # Convert the model to the TensorFlow Lite format with quantization\n","    converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n","    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","    converter.representative_dataset = representative_dataset_test\n","    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]  # TFLITE_BUILTINS_INT8]\n","    converter.inference_input_type = tf.uint8  # tf.lite.constants.INT8\n","    converter.inference_output_type = tf.uint8\n","\n","    tflite_model = converter.convert()\n","\n","    open(tflite_model_file, \"wb\").write(tflite_model)\n","\n","\n","def compare_model_kerasandtflite(audio_file, keras_model_file, tflite_model_file, trim_flag=True, same_training=False):\n","    feature = get_STFT(audio_file, trim_flag=trim_flag, same_training=same_training)\n","    model_keras = load_model(keras_model_file)\n","    step = 10\n","    for i in range(0, feature.shape[0], step):\n","        new_feature = feature[i:i + step]\n","\n","        mfccs = librosa.feature.mfcc(y=new_feature, sr=16000, n_mfcc=13)\n","        mfccs = np.mean(mfccs.T, axis=0)\n","        mfccs = mfccs.flatten()\n","\n","        pad = pad_features(mfccs, target_length)\n","\n","        new_feature = pad\n","\n","        pred = model_keras.predict(np.asarray([new_feature]), verbose=0)\n","\n","        interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n","        interpreter.allocate_tensors()\n","\n","        input_details = interpreter.get_input_details()[0]\n","        output_details = interpreter.get_output_details()[0]\n","\n","        test_audio = new_feature\n","\n","        if input_details[\"dtype\"] == np.uint8:\n","            input_scale, input_zero_point = input_details[\"quantization\"]\n","            test_audio = test_audio / input_scale + input_zero_point\n","            test_audio = np.around(test_audio)\n","\n","        test_audio = test_audio.astype(input_details[\"dtype\"])\n","        interpreter.set_tensor(input_details[\"index\"], [test_audio])\n","        interpreter.invoke()\n","        output = interpreter.get_tensor(output_details[\"index\"])[0]\n","\n","        output_type = output_details[\"dtype\"]\n","        if output_type == np.uint8:\n","            output_scale, output_zero_point = output_details[\"quantization\"]\n","            output = output_scale * (output.astype(np.float32) - output_zero_point)\n","        out_label = \"\"\n","        if np.argmax(output) == 0:\n","            out_label = \"Water\"\n","        elif np.argmax(output) == 1:\n","            out_label = \"Other\"\n","        else:\n","            out_label = \"Alarm\"\n","        print(f\"output:{i} / uint8 tflite-> {output}: keras-> {pred[0]}, label: {out_label}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JL43N4tQbAWK"},"outputs":[],"source":["feature_folder = \"features_new\"\n","audio_folder = \"data/balanced/inference\"\n","\n","audio_file = os.path.join(audio_folder, \"Alarm.wav\")\n","keras_model_file = os.path.join(\"weights\", \"mfcc_512_93%_model_16k_1.3.weights.h5\")\n","tflite_model_file = os.path.join(\"weights\", \"mfcc_512_93%_model_16k_1.3.weights.tflite\")\n","\n","\n","same_training = True\n","trim_flag = True\n","\n","print(\"\\n\\n\\n====================== Convert keras to qt tflite model ======================\\n\\n\\n\")\n","# \"\"\" # Do convert model from keras to quantized tflite \"\"\"\n","# convert_keras2qttflite(feature_folder, keras_model_file, tflite_model_file)\n","\n","print(\"\\n\\n\\n====================== Compare keras to qt tflite model ======================\\n\\n\\n\")\n","\"\"\" # # Compare model with origin \"\"\""]},{"cell_type":"code","source":["audio_file = os.path.join(\"data/balanced/test/Alarm/a (207).wav\")\n","\n","compare_model_kerasandtflite(audio_file, keras_model_file, tflite_model_file, trim_flag=trim_flag, same_training=same_training)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YON_zBxZg3et","executionInfo":{"status":"ok","timestamp":1724161519611,"user_tz":-300,"elapsed":30445,"user":{"displayName":"Student SE","userId":"15057726547341965574"}},"outputId":"a334aba9-3d6c-49d9-f6e3-0c91a5ace33a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=495\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["output:0 / uint8 tflite-> [0.         0.         0.99609375]: keras-> [0. 0. 1.], label: Alarm\n","output:10 / uint8 tflite-> [0.         0.         0.99609375]: keras-> [0. 0. 1.], label: Alarm\n","output:20 / uint8 tflite-> [0.         0.         0.99609375]: keras-> [0. 0. 1.], label: Alarm\n","output:30 / uint8 tflite-> [0.         0.         0.99609375]: keras-> [0. 0. 1.], label: Alarm\n","output:40 / uint8 tflite-> [0.         0.99609375 0.        ]: keras-> [0.000000e+00 1.000000e+00 5.828338e-18], label: Water\n","output:50 / uint8 tflite-> [0.         0.         0.99609375]: keras-> [0. 0. 1.], label: Alarm\n","output:60 / uint8 tflite-> [0.         0.         0.99609375]: keras-> [0. 0. 1.], label: Alarm\n","output:70 / uint8 tflite-> [0.         0.         0.99609375]: keras-> [0. 0. 1.], label: Alarm\n","output:80 / uint8 tflite-> [0.         0.         0.99609375]: keras-> [0. 0. 1.], label: Alarm\n","output:90 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Other\n","output:100 / uint8 tflite-> [0.         0.         0.99609375]: keras-> [0. 0. 1.], label: Alarm\n","output:110 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1.0000000e+00 9.5264905e-33 0.0000000e+00], label: Other\n","output:120 / uint8 tflite-> [0.         0.         0.99609375]: keras-> [0. 0. 1.], label: Alarm\n","output:130 / uint8 tflite-> [0.         0.         0.99609375]: keras-> [0. 0. 1.], label: Alarm\n","output:140 / uint8 tflite-> [0.         0.         0.99609375]: keras-> [0. 0. 1.], label: Alarm\n","output:150 / uint8 tflite-> [0.         0.         0.99609375]: keras-> [0. 0. 1.], label: Alarm\n","output:160 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1.0000000e+00 1.7303598e-28 0.0000000e+00], label: Other\n","output:170 / uint8 tflite-> [0.         0.99609375 0.        ]: keras-> [0. 1. 0.], label: Water\n","output:180 / uint8 tflite-> [0.         0.         0.99609375]: keras-> [0. 0. 1.], label: Alarm\n","output:190 / uint8 tflite-> [0.         0.99609375 0.        ]: keras-> [7.2752062e-34 1.0000000e+00 3.4402166e-08], label: Water\n","output:200 / uint8 tflite-> [0.         0.         0.99609375]: keras-> [0. 0. 1.], label: Alarm\n","output:210 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Other\n","output:220 / uint8 tflite-> [0.         0.99609375 0.        ]: keras-> [0. 1. 0.], label: Water\n","output:230 / uint8 tflite-> [0.         0.         0.99609375]: keras-> [0. 0. 1.], label: Alarm\n","output:240 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Other\n","output:250 / uint8 tflite-> [0.97265625 0.02734375 0.        ]: keras-> [0.97428685 0.02571316 0.        ], label: Other\n"]}]},{"cell_type":"code","source":["audio_file = os.path.join(\"data/balanced/test/Water/water5_339.wav\")\n","\n","compare_model_kerasandtflite(audio_file, keras_model_file, tflite_model_file, trim_flag=trim_flag, same_training=same_training)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aIiJ7LAehVh5","executionInfo":{"status":"ok","timestamp":1724161667797,"user_tz":-300,"elapsed":5691,"user":{"displayName":"Student SE","userId":"15057726547341965574"}},"outputId":"d919bf02-8116-4211-b1cb-085ccd9b0f8e"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"]},{"output_type":"stream","name":"stdout","text":["output:0 / uint8 tflite-> [0.         0.         0.99609375]: keras-> [0. 0. 1.], label: Alarm\n","output:10 / uint8 tflite-> [0.         0.         0.99609375]: keras-> [0. 0. 1.], label: Alarm\n","output:20 / uint8 tflite-> [0.         0.         0.99609375]: keras-> [0. 0. 1.], label: Alarm\n","output:30 / uint8 tflite-> [0.         0.         0.99609375]: keras-> [0. 0. 1.], label: Alarm\n","output:40 / uint8 tflite-> [0.         0.         0.99609375]: keras-> [6.8508787e-16 7.4933365e-17 1.0000000e+00], label: Alarm\n","output:50 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1.0000000e+00 1.6057102e-26 0.0000000e+00], label: Water\n","output:60 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [9.9999976e-01 2.9199893e-07 2.5884388e-12], label: Water\n","output:70 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1.0000000e+00 1.0506623e-20 0.0000000e+00], label: Water\n","output:80 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Water\n","output:90 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Water\n","output:100 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Water\n","output:110 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Water\n","output:120 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Water\n","output:130 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Water\n","output:140 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Water\n","output:150 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Water\n","output:160 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Water\n","output:170 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Water\n","output:180 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Water\n","output:190 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Water\n","output:200 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Water\n","output:210 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Water\n","output:220 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Water\n","output:230 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Water\n","output:240 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Water\n","output:250 / uint8 tflite-> [0.         0.99609375 0.        ]: keras-> [0. 1. 0.], label: Other\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}