{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO0mWep7tBMlLFg3BoGlFqT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zQWDZGtTbT2S","executionInfo":{"status":"ok","timestamp":1718145118658,"user_tz":-300,"elapsed":32774,"user":{"displayName":"Revel Darling","userId":"13220393462657329038"}},"outputId":"09b90e8f-c54c-4923-b6cc-fb7c23ae86d6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"XPBN4vhsayqZ","executionInfo":{"status":"ok","timestamp":1718145121340,"user_tz":-300,"elapsed":2688,"user":{"displayName":"Revel Darling","userId":"13220393462657329038"}}},"outputs":[],"source":["import glob\n","import os\n","import numpy as np\n","import librosa\n","import sys\n","import tensorflow as tf\n","from keras.models import load_model\n","\n","target_length = 3341"]},{"cell_type":"code","source":["os.chdir('/content/drive/MyDrive/Projects/AlarmWaterClassification')"],"metadata":{"id":"lWu8W9Swb3IG","executionInfo":{"status":"ok","timestamp":1718145234740,"user_tz":-300,"elapsed":3,"user":{"displayName":"Revel Darling","userId":"13220393462657329038"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def pad_features(features, target_length):\n","    if len(features) < target_length:\n","        padded_features = np.zeros((target_length, 1))\n","        padded_features[:len(features), 0] = features\n","    else:\n","        padded_features = features[:target_length]\n","        padded_features = padded_features.reshape(-1, 1)  # Ensure it has the shape (timesteps, channels)\n","    return padded_features\n","\n","def get_STFT(file, trim_flag=False, same_training=False):\n","    audio_data, sample_rate = librosa.load(file, sr=16000)\n","\n","    zero_data = np.zeros((160,))\n","    audio_data = zero_data.tolist() + audio_data.tolist()\n","    audio_data = np.array(audio_data)\n","    audio_data[480:512] = 0\n","    reduced_noise = audio_data\n","\n","    trimmed = reduced_noise\n","    if trim_flag or same_training:\n","        trimmed, index = librosa.effects.trim(reduced_noise, top_db=20, frame_length=512, hop_length=64)\n","    # extract features\n","    if same_training:\n","        stft = np.abs(librosa.stft(trimmed, n_fft=512, hop_length=256, win_length=512))\n","    else:\n","        stft = np.abs(librosa.stft(trimmed, n_fft=512, hop_length=320, win_length=480, center=False))\n","\n","    return stft\n","\n","\n","def create_feature_data(audio_folder, folder_name=\"features_new\", trim_flag=True, same_training=True):\n","    os.makedirs(folder_name, exist_ok=True)\n","    list_data_audio = glob.glob(f\"{audio_folder}*.wav\", recursive=True)\n","    step = 100\n","    for fa in list_data_audio:\n","        feature = get_STFT(fa, trim_flag=trim_flag, same_training=same_training)\n","        feature = feature.T\n","        file_name = fa.split(\"\\\\\")[-1]\n","        dir_name = os.path.dirname(fa)\n","\n","        os.makedirs(os.path.join(folder_name, dir_name), exist_ok=True)\n","\n","        for i in range(0, feature.shape[0], step):\n","            new_feature = feature[i:i + step]\n","\n","            mfccs = librosa.feature.mfcc(y=new_feature, sr=16000, n_mfcc=13)\n","            mfccs = np.mean(mfccs.T, axis=0)\n","            mfccs = mfccs.flatten()\n","\n","            pad = pad_features(mfccs, target_length)\n","\n","            np.save(f\"{folder_name}/{file_name}_{i}.npy\", pad)\n","\n","\n","def convert_keras2qttflite(feature_folder, keras_model_file, tflite_model_file):\n","    def representative_dataset_test():\n","        list_np = glob.glob(f\"{feature_folder}/**/*.npy\", recursive=True)\n","        for np_f in list_np:\n","            np_data = np.load(np_f)\n","            np_data = np.array(np_data, dtype=np.float32, ndmin=2)\n","            yield [np.expand_dims(np_data, axis=0)]\n","\n","    keras_model = load_model(keras_model_file)\n","    # Convert the model to the TensorFlow Lite format with quantization\n","    converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n","    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","    converter.representative_dataset = representative_dataset_test\n","    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]  # TFLITE_BUILTINS_INT8]\n","    converter.inference_input_type = tf.uint8  # tf.lite.constants.INT8\n","    converter.inference_output_type = tf.uint8\n","\n","    tflite_model = converter.convert()\n","\n","    open(tflite_model_file, \"wb\").write(tflite_model)\n","\n","\n","def compare_model_kerasandtflite(audio_file, keras_model_file, tflite_model_file, trim_flag=True, same_training=False):\n","    feature = get_STFT(audio_file, trim_flag=trim_flag, same_training=same_training)\n","    feature = feature.T\n","    model_keras = load_model(keras_model_file)\n","    step = 10\n","    for i in range(0, feature.shape[0], step):\n","        new_feature = feature[i:i + step]\n","\n","        mfccs = librosa.feature.mfcc(y=new_feature, sr=16000, n_mfcc=13)\n","        mfccs = np.mean(mfccs.T, axis=0)\n","        mfccs = mfccs.flatten()\n","\n","        pad = pad_features(mfccs, target_length)\n","\n","        new_feature = pad\n","\n","        pred = model_keras.predict(np.asarray([new_feature]), verbose=0)\n","\n","        interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n","        interpreter.allocate_tensors()\n","\n","        input_details = interpreter.get_input_details()[0]\n","        output_details = interpreter.get_output_details()[0]\n","\n","        test_audio = new_feature\n","\n","        if input_details[\"dtype\"] == np.uint8:\n","            input_scale, input_zero_point = input_details[\"quantization\"]\n","            test_audio = test_audio / input_scale + input_zero_point\n","            test_audio = np.around(test_audio)\n","\n","        test_audio = test_audio.astype(input_details[\"dtype\"])\n","        interpreter.set_tensor(input_details[\"index\"], [test_audio])\n","        interpreter.invoke()\n","        output = interpreter.get_tensor(output_details[\"index\"])[0]\n","\n","        output_type = output_details[\"dtype\"]\n","        if output_type == np.uint8:\n","            output_scale, output_zero_point = output_details[\"quantization\"]\n","            output = output_scale * (output.astype(np.float32) - output_zero_point)\n","        out_label = \"\"\n","        if np.argmax(output) == 0:\n","            out_label = \"Alarm\"\n","        elif np.argmax(output) == 1:\n","            out_label = \"Water\"\n","        else:\n","            out_label = \"Other\"\n","        print(f\"output:{i} / uint8 tflite-> {output}: keras-> {pred[0]}, label: {out_label}\")\n"],"metadata":{"id":"N0qvX61Ma8qY","executionInfo":{"status":"ok","timestamp":1718147246574,"user_tz":-300,"elapsed":622,"user":{"displayName":"Revel Darling","userId":"13220393462657329038"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["feature_folder = \"features_new\"\n","audio_folder = \"data/inference\"\n","\n","audio_file = os.path.join(audio_folder, \"Alarm.wav\")\n","keras_model_file = os.path.join(\"weights\", \"model_16k_1.3.weights.h5\")\n","tflite_model_file = os.path.join(\"weights\", \"model_16k_quantized_1.3.tflite\")\n","\n","# if not os.path.exists(tflite_model_file):\n","#     pass\n","# else:\n","#     print(f\"\\nthe same file name already exists: {tflite_model_file}\")\n","#     sys.exit(\"error !\")\n","\n","same_training = True\n","trim_flag = True\n","# Create feature data numpy from audio\n","\"\"\" same_training to make data feature same with training proceed.\n","audio_folder: should be small engough each type class its number is 10 files\"\"\"\n","print(\"\\n\\n\\n====================== Create feature data ======================\\n\\n\\n\")\n","create_feature_data(audio_folder, feature_folder, trim_flag=trim_flag, same_training=same_training)\n","\n","print(\"\\n\\n\\n====================== Convert keras to qt tflite model ======================\\n\\n\\n\")\n","\"\"\" # Do convert model from keras to quantized tflite \"\"\"\n","convert_keras2qttflite(feature_folder, keras_model_file, tflite_model_file)\n","\n","print(\"\\n\\n\\n====================== Compare keras to qt tflite model ======================\\n\\n\\n\")\n","\"\"\" # # Compare model with origin \"\"\"\n","compare_model_kerasandtflite(audio_file, keras_model_file, tflite_model_file, trim_flag=trim_flag, same_training=same_training)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JL43N4tQbAWK","executionInfo":{"status":"ok","timestamp":1718147330312,"user_tz":-300,"elapsed":83004,"user":{"displayName":"Revel Darling","userId":"13220393462657329038"}},"outputId":"aa4a735e-b30c-4799-90ce-1db3a386ec16"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\n","====================== Create feature data ======================\n","\n","\n","\n","\n","\n","\n","====================== Convert keras to qt tflite model ======================\n","\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","\n","====================== Compare keras to qt tflite model ======================\n","\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=257\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["output:0 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:10 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:20 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:30 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:40 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:50 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:60 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:70 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:80 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:90 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:100 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:110 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:120 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:130 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:140 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:150 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:160 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:170 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:180 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:190 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:200 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:210 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:220 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:230 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1.000000e+00 7.873228e-24 0.000000e+00], label: Alarm\n","output:240 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:250 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:260 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:270 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:280 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:290 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:300 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1. 0. 0.], label: Alarm\n","output:310 / uint8 tflite-> [0.99609375 0.         0.        ]: keras-> [1.0000000e+00 5.5570256e-34 0.0000000e+00], label: Alarm\n"]}]},{"cell_type":"code","source":["np.load('features_16k/class_names.npy')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6MkgLSpHbl25","executionInfo":{"status":"ok","timestamp":1718146329336,"user_tz":-300,"elapsed":512,"user":{"displayName":"Revel Darling","userId":"13220393462657329038"}},"outputId":"afb672b9-d4a4-4118-e680-c10f36c0976d"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['Alarm', 'Water', 'Other'], dtype='<U5')"]},"metadata":{},"execution_count":20}]}]}