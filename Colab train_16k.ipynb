{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm14SqI_3zFu"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhrNu_bHwUGz",
        "outputId": "c6954354-6c2c-4325-cf24-c31b6ef20851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51n1PU9V3tgS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization, \\\n",
        "                                            Add, LSTM, Bidirectional\n",
        "\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from collections import Counter\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCzZM2eV4P4Q"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"/content/drive/MyDrive/Projects/AlarmWaterClassification\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilies"
      ],
      "metadata": {
        "id": "-SMX4jd8eTxZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9j4NIN1cQhr"
      },
      "outputs": [],
      "source": [
        "def print_M(conf_M, class_names):\n",
        "    s = \"activity,\" + \",\".join(class_names)\n",
        "    print(s)\n",
        "    for i, row in enumerate(conf_M):\n",
        "        print(class_names[i] + \",\" + \",\".join(map(str, row)))\n",
        "\n",
        "def print_M_P(conf_M, class_names):\n",
        "    s = \"activity,\" + \",\".join(class_names)\n",
        "    print(s)\n",
        "    for i, row in enumerate(conf_M):\n",
        "        total = sum(row)\n",
        "        percentages = [str(round(val / total, 2)) if total > 0 else '0' for val in row]\n",
        "        print(class_names[i] + \",\" + \",\".join(percentages))\n",
        "\n",
        "def showResult(result, y_test, class_names):\n",
        "    predictions = [np.argmax(y) for y in result]\n",
        "    expected = [np.argmax(y) for y in y_test]\n",
        "\n",
        "    num_labels = y_test.shape[1]\n",
        "    conf_M = [[0] * num_labels for _ in range(num_labels)]\n",
        "\n",
        "    for e, p in zip(expected, predictions):\n",
        "        conf_M[e][p] += 1\n",
        "\n",
        "    print_M(conf_M, class_names)\n",
        "    print_M_P(conf_M, class_names)\n",
        "\n",
        "def load_weight(path):\n",
        "    model = load_model(path)\n",
        "    print(model.summary())\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "xGLUragxjqEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_improved_model(input_shape, num_labels):\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, input_shape=input_shape, return_sequences=True))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(LSTM(64))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(128))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(num_labels))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "u0H3mg6Tu9n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "9FvJ70G7eWDr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loading"
      ],
      "metadata": {
        "id": "ceKM0a6B2za2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_weight_out = os.path.join('weights', 'exp_model_16k_1.3.weights.h5')\n",
        "\n",
        "# if os.path.exists(model_weight_out):\n",
        "#     sys.exit(f\"The same file name exists already: {model_weight_out}\")\n",
        "\n",
        "############### Loading the datasets #####################\n",
        "\n",
        "print('\\nLoading the data\\n')\n",
        "\n",
        "featuresPath = \"features_16k_single_stft/\"\n",
        "\n",
        "class_names = np.load(os.path.join(featuresPath, 'class_names.npy'))\n",
        "\n",
        "X_train = np.load(os.path.join(featuresPath, 'X_train.npy'))\n",
        "y_train = np.load(os.path.join(featuresPath, 'y_train.npy'))\n",
        "\n",
        "X_val = np.load(os.path.join(featuresPath, 'X_val.npy'))\n",
        "y_val = np.load(os.path.join(featuresPath, 'y_val.npy'))\n",
        "\n",
        "X_test = np.load(os.path.join(featuresPath, 'X_test.npy'))\n",
        "y_test = np.load(os.path.join(featuresPath, 'y_test.npy'))\n",
        "\n",
        "num_labels = y_train.shape[1]"
      ],
      "metadata": {
        "id": "zuKi2K9Ed4ge",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1031526b-c66c-4e08-df31-f78c25f7f021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading the data\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Balancing"
      ],
      "metadata": {
        "id": "D_60aUNEeYYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nBalancing the data\\n\")\n",
        "\n",
        "print(\"Train Class distribution before balancing:\", Counter(np.argmax(y_train, axis=1)))\n",
        "\n",
        "# Upsampling using SMOTE\n",
        "smote = SMOTE(sampling_strategy={1: 10000, 2: 9000})\n",
        "oversampled_features, oversampled_labels = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Downsampling using RandomUnderSampler\n",
        "undersampler = RandomUnderSampler(sampling_strategy={0: 7300})\n",
        "undersampled_features, undersampled_labels = undersampler.fit_resample(\n",
        "    oversampled_features, oversampled_labels)\n",
        "\n",
        "print(\"Train Class distribution after balancing:\", Counter(\n",
        "    np.argmax(undersampled_labels, axis=1)))\n",
        "\n",
        "X_train = undersampled_features\n",
        "y_train = undersampled_labels"
      ],
      "metadata": {
        "id": "jmToVv-sd_La",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "282fdaa0-1ca1-485e-cf2f-c797637a4c3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Balancing the data\n",
            "\n",
            "Train Class distribution before balancing: Counter({0: 7343, 1: 4309, 2: 842})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (10000) in class 1 will be larger than the number of samples in the majority class (class #0 -> 7343)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (9000) in class 2 will be larger than the number of samples in the majority class (class #0 -> 7343)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Class distribution after balancing: Counter({1: 10000, 2: 9000, 0: 7300})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "yTmuUEE8eaTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.expand_dims(X_train, axis=1)\n",
        "X_val = np.expand_dims(X_val, axis=1)\n",
        "X_test = np.expand_dims(X_test, axis=1)"
      ],
      "metadata": {
        "id": "vplSLLgYCSkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###################### Training the model ###########################3\n",
        "print(\"\\nTraining the model\\n\")\n",
        "\n",
        "input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "model = build_improved_model(input_shape, num_labels)\n",
        "# model.summary()\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 10:\n",
        "        return lr\n",
        "    else:\n",
        "        return float(lr * tf.math.exp(-0.1))\n",
        "\n",
        "callback = LearningRateScheduler(scheduler)\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=32, epochs=30,\n",
        "          validation_data=(X_val, y_val),\n",
        "          callbacks=[callback])"
      ],
      "metadata": {
        "id": "yTCYIHY_eEcq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7034524-06f2-4c0d-ef8a-1714b0d49dd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training the model\n",
            "\n",
            "Epoch 1/30\n",
            "822/822 [==============================] - 6s 7ms/step - loss: 0.6693 - accuracy: 0.7141 - val_loss: 1.3514 - val_accuracy: 0.5824 - lr: 3.6788e-04\n",
            "Epoch 2/30\n",
            "822/822 [==============================] - 6s 7ms/step - loss: 0.6666 - accuracy: 0.7168 - val_loss: 1.3133 - val_accuracy: 0.5853 - lr: 3.6788e-04\n",
            "Epoch 3/30\n",
            "822/822 [==============================] - 5s 6ms/step - loss: 0.6660 - accuracy: 0.7168 - val_loss: 1.2918 - val_accuracy: 0.5839 - lr: 3.6788e-04\n",
            "Epoch 4/30\n",
            "822/822 [==============================] - 6s 8ms/step - loss: 0.6646 - accuracy: 0.7188 - val_loss: 1.2550 - val_accuracy: 0.5889 - lr: 3.6788e-04\n",
            "Epoch 5/30\n",
            "822/822 [==============================] - 5s 7ms/step - loss: 0.6629 - accuracy: 0.7196 - val_loss: 1.2498 - val_accuracy: 0.5860 - lr: 3.6788e-04\n",
            "Epoch 6/30\n",
            "822/822 [==============================] - 6s 7ms/step - loss: 0.6633 - accuracy: 0.7165 - val_loss: 1.1977 - val_accuracy: 0.5875 - lr: 3.6788e-04\n",
            "Epoch 7/30\n",
            "822/822 [==============================] - 6s 8ms/step - loss: 0.6626 - accuracy: 0.7191 - val_loss: 1.2285 - val_accuracy: 0.5868 - lr: 3.6788e-04\n",
            "Epoch 8/30\n",
            "822/822 [==============================] - 5s 6ms/step - loss: 0.6587 - accuracy: 0.7190 - val_loss: 1.1856 - val_accuracy: 0.5868 - lr: 3.6788e-04\n",
            "Epoch 9/30\n",
            "822/822 [==============================] - 6s 8ms/step - loss: 0.6580 - accuracy: 0.7187 - val_loss: 1.2602 - val_accuracy: 0.5860 - lr: 3.6788e-04\n",
            "Epoch 10/30\n",
            "822/822 [==============================] - 5s 6ms/step - loss: 0.6571 - accuracy: 0.7200 - val_loss: 1.2922 - val_accuracy: 0.5860 - lr: 3.6788e-04\n",
            "Epoch 11/30\n",
            "822/822 [==============================] - 6s 7ms/step - loss: 0.6597 - accuracy: 0.7209 - val_loss: 1.3252 - val_accuracy: 0.5860 - lr: 3.3287e-04\n",
            "Epoch 12/30\n",
            "822/822 [==============================] - 6s 7ms/step - loss: 0.6532 - accuracy: 0.7232 - val_loss: 1.3836 - val_accuracy: 0.5875 - lr: 3.0119e-04\n",
            "Epoch 13/30\n",
            "822/822 [==============================] - 5s 6ms/step - loss: 0.6495 - accuracy: 0.7230 - val_loss: 1.3065 - val_accuracy: 0.5839 - lr: 2.7253e-04\n",
            "Epoch 14/30\n",
            "822/822 [==============================] - 6s 8ms/step - loss: 0.6540 - accuracy: 0.7241 - val_loss: 1.3285 - val_accuracy: 0.5875 - lr: 2.4660e-04\n",
            "Epoch 15/30\n",
            "822/822 [==============================] - 5s 6ms/step - loss: 0.6499 - accuracy: 0.7243 - val_loss: 1.2712 - val_accuracy: 0.5853 - lr: 2.2313e-04\n",
            "Epoch 16/30\n",
            "822/822 [==============================] - 6s 7ms/step - loss: 0.6480 - accuracy: 0.7249 - val_loss: 1.2576 - val_accuracy: 0.5875 - lr: 2.0190e-04\n",
            "Epoch 17/30\n",
            "822/822 [==============================] - 6s 7ms/step - loss: 0.6492 - accuracy: 0.7240 - val_loss: 1.2309 - val_accuracy: 0.5875 - lr: 1.8268e-04\n",
            "Epoch 18/30\n",
            "822/822 [==============================] - 5s 6ms/step - loss: 0.6460 - accuracy: 0.7245 - val_loss: 1.2801 - val_accuracy: 0.5875 - lr: 1.6530e-04\n",
            "Epoch 19/30\n",
            "822/822 [==============================] - 6s 8ms/step - loss: 0.6480 - accuracy: 0.7256 - val_loss: 1.2850 - val_accuracy: 0.5868 - lr: 1.4957e-04\n",
            "Epoch 20/30\n",
            "822/822 [==============================] - 5s 6ms/step - loss: 0.6468 - accuracy: 0.7240 - val_loss: 1.3161 - val_accuracy: 0.5853 - lr: 1.3534e-04\n",
            "Epoch 21/30\n",
            "822/822 [==============================] - 6s 7ms/step - loss: 0.6443 - accuracy: 0.7249 - val_loss: 1.3639 - val_accuracy: 0.5860 - lr: 1.2246e-04\n",
            "Epoch 22/30\n",
            "822/822 [==============================] - 6s 7ms/step - loss: 0.6434 - accuracy: 0.7254 - val_loss: 1.3297 - val_accuracy: 0.5875 - lr: 1.1080e-04\n",
            "Epoch 23/30\n",
            "822/822 [==============================] - 5s 6ms/step - loss: 0.6442 - accuracy: 0.7281 - val_loss: 1.3068 - val_accuracy: 0.5853 - lr: 1.0026e-04\n",
            "Epoch 24/30\n",
            "822/822 [==============================] - 6s 8ms/step - loss: 0.6431 - accuracy: 0.7274 - val_loss: 1.2944 - val_accuracy: 0.5860 - lr: 9.0718e-05\n",
            "Epoch 25/30\n",
            "822/822 [==============================] - 5s 6ms/step - loss: 0.6454 - accuracy: 0.7267 - val_loss: 1.2899 - val_accuracy: 0.5868 - lr: 8.2085e-05\n",
            "Epoch 26/30\n",
            "822/822 [==============================] - 6s 8ms/step - loss: 0.6436 - accuracy: 0.7248 - val_loss: 1.2872 - val_accuracy: 0.5875 - lr: 7.4273e-05\n",
            "Epoch 27/30\n",
            "822/822 [==============================] - 5s 7ms/step - loss: 0.6439 - accuracy: 0.7302 - val_loss: 1.3467 - val_accuracy: 0.5868 - lr: 6.7205e-05\n",
            "Epoch 28/30\n",
            "822/822 [==============================] - 6s 7ms/step - loss: 0.6439 - accuracy: 0.7259 - val_loss: 1.3203 - val_accuracy: 0.5875 - lr: 6.0810e-05\n",
            "Epoch 29/30\n",
            "822/822 [==============================] - 6s 8ms/step - loss: 0.6428 - accuracy: 0.7306 - val_loss: 1.3070 - val_accuracy: 0.5889 - lr: 5.5023e-05\n",
            "Epoch 30/30\n",
            "822/822 [==============================] - 6s 7ms/step - loss: 0.6373 - accuracy: 0.7290 - val_loss: 1.3266 - val_accuracy: 0.5896 - lr: 4.9787e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d1f80110dc0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "f24jMba7egKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTesting the model\\n\")\n",
        "\n",
        "result = model.predict(X_test)\n",
        "\n",
        "cnt, cnt_alarm, cnt_other, cnt_water = 0, 0, 0, 0\n",
        "alarm_num, other_num, water_num = (sum(np.argmax(y_test, axis=1) == 0),\n",
        "                                    sum(np.argmax(y_test, axis=1) == 1),\n",
        "                                    sum(np.argmax(y_test, axis=1) == 2))\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "    pred = np.argmax(result[i])\n",
        "    if np.argmax(y_test[i]) == pred:\n",
        "        cnt += 1\n",
        "        if pred == 0:\n",
        "            cnt_alarm += 1\n",
        "        elif pred == 1:\n",
        "            cnt_other += 1\n",
        "        else:\n",
        "            cnt_water += 1\n",
        "\n",
        "acc = round(cnt * 100 / len(y_test), 2)\n",
        "acc_alarm = round(cnt_alarm * 100 / alarm_num, 2)\n",
        "acc_other = round(cnt_other * 100 / other_num, 2)\n",
        "acc_water = round(cnt_water * 100 / water_num, 2)\n",
        "\n",
        "print(\n",
        "    f\"Total Accuracy: {acc}%, Alarm Accuracy: {acc_alarm}%, Others Accuracy: {acc_other}%, Water Accuracy: {acc_water}%\")\n",
        "\n",
        "showResult(result, y_test, class_names)\n",
        "\n",
        "print(\"\\n\")\n",
        "print(classification_report(\n",
        "    np.argmax(y_test, axis=1),\n",
        "    np.argmax(result, axis=1),\n",
        "    target_names=list(class_names)\n",
        "))"
      ],
      "metadata": {
        "id": "FaLtMwleeJTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e02a1bd8-8325-4650-e6d6-0e6c77204580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing the model\n",
            "\n",
            "23/23 [==============================] - 0s 2ms/step\n",
            "Total Accuracy: 56.53%, Alarm Accuracy: 46.71%, Others Accuracy: 68.15%, Water Accuracy: 84.78%\n",
            "activity,Alarm,Water,Other\n",
            "Alarm,199,155,72\n",
            "Water,8,169,71\n",
            "Other,1,6,39\n",
            "activity,Alarm,Water,Other\n",
            "Alarm,0.47,0.36,0.17\n",
            "Water,0.03,0.68,0.29\n",
            "Other,0.02,0.13,0.85\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Alarm       0.96      0.47      0.63       426\n",
            "       Water       0.51      0.68      0.58       248\n",
            "       Other       0.21      0.85      0.34        46\n",
            "\n",
            "    accuracy                           0.57       720\n",
            "   macro avg       0.56      0.67      0.52       720\n",
            "weighted avg       0.76      0.57      0.59       720\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving"
      ],
      "metadata": {
        "id": "honv7JLKoIPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if not os.path.exists(\"Models\"):\n",
        "#     os.makedirs(\"Models\")\n",
        "# path = os.path.join(\"Models\", f\"audio_NN_New{datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}_acc_{acc}\")\n",
        "# model_json = model.to_json()\n",
        "# with open(f\"{path}.json\", \"w\") as json_file:\n",
        "#     json_file.write(model_json)\n",
        "# model.save_weights(f\"{path}.weights.h5\")\n",
        "\n",
        "# if not os.path.exists(\"weights\"):\n",
        "#     os.makedirs(\"weights\")\n",
        "# # model.save(model_weight_out, overwrite=True, include_optimizer=False)\n",
        "\n",
        "# model.save('weights/bilstm_83_exp_model_16k_1.3.weights.h5', overwrite=True, include_optimizer=False)"
      ],
      "metadata": {
        "id": "bwP5-9BnoH_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loaded_model = tf.keras.models.load_model('weights/bilstm_83_exp_model_16k_1.3.weights.h5')"
      ],
      "metadata": {
        "id": "fqQzZHUrjW3e"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}